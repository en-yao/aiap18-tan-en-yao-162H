{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995c6736",
   "metadata": {},
   "source": [
    "### 1. Importing the required libraries for EDA\n",
    "Below are the libraries that are used in order to perform EDA (Exploratory data analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "466ca52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bc1429",
   "metadata": {},
   "source": [
    "### 2. Loading the data into the data frame\n",
    "We first make a connection to the database and then use pandas to query from that database into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfa8176c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "unable to open database file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13928\\3359494283.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/calls.db'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT * FROM calls\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOperationalError\u001b[0m: unable to open database file"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('data/calls.db')\n",
    "df = pd.read_sql_query(\"SELECT * FROM calls\", conn)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ae57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d60943",
   "metadata": {},
   "source": [
    "### 3. Checking the types of data\n",
    "Here we check the datatypes because sometimes integer values, like in call duration or financial loss, would be stored as a string. If in that case, we have to convert that string to the integer data, only then we can plot the data via a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec58c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded02377",
   "metadata": {},
   "source": [
    "### 4. Dropping irrelevant columns\n",
    "Sometimes there would be columns that we never use in such cases dropping is the only solution. In this case, I found the columns Device Battery and Timestamp not useful so I just dropped that for this instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbd3abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Device Battery', 'Timestamp'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f7e8cf",
   "metadata": {},
   "source": [
    "### 5. Dropping the duplicate rows\n",
    "This can sometimes occur due to data entry errors, leading to redundant information. Hence the need to check for duplicates and remove them if any. In this case, we found 2000 duplicated rows and after removing them, we are left with 10000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953ef94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e7fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows_df = df[df.duplicated()]\n",
    "print(\"number of duplicate rows: \", duplicate_rows_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0b37d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ff14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69818116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df41adc",
   "metadata": {},
   "source": [
    "### 6. Replacing missing values with mean\n",
    "The missing values in Financial Loss has a significant percentage of about 11.3%, hence the best way to handle this is to replace the missing values with either the average, mode or median. In this case we shall replace the missing values with just the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b01a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0346ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Financial Loss'].fillna(df['Financial Loss'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb073d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd89a5",
   "metadata": {},
   "source": [
    "### 7. Dropping negative values\n",
    "Some negative values are present in Call Duration and Financial Loss. This may happen due to error in data entry but I do not expect negative values to be present in features like Call Duration and Financial Loss, hence I dropped them for this instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf5865",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fbe7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f657b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[['Call Duration', 'Financial Loss']] >= 0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee1a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14158cb",
   "metadata": {},
   "source": [
    "### 8. Checking Category Uniqueness\n",
    "We check for category uniqueness because sometimes two or more categories can actually be the same. If so, we combine the categories to avoid misrepresentation of the data. In this case, columns Country Prefix and Call Type each have two categories which are in fact the same but are just spelt or represented differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe6a35b",
   "metadata": {},
   "source": [
    "- In Country Prefix, there is a category MM which does not fit the rest of the categories but turns out that is the country code for Myanmar. It just so happens that the Maynmar dialing code is 95, which is one of the categories.\n",
    "\n",
    "- In Call Type, WhatsApp and Whats App represent 2 different categories when they should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01bf677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country Prefix'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7788ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Call Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90b7942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country Prefix'] = df['Country Prefix'].replace('MM', '95')\n",
    "df['Call Type'] = df['Call Type'].replace('Whats App', 'WhatsApp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802b9232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country Prefix'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b4baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Call Type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8616b9",
   "metadata": {},
   "source": [
    "### 9. Plotting histograms, distribution graphs and pairplots\n",
    "\n",
    "#### Histograms and Distribution graphs\n",
    "Also known as univariate analysis, we examine each feature and look into the distributions, patterns, and characteristics before exploring relationships with other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145dad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['Call Duration', 'Call Frequency', 'Financial Loss', 'Previous Contact Count']\n",
    "cat_cols = ['Flagged by Carrier', 'Is International', 'Country Prefix', 'Call Type', 'Scam Call']\n",
    "\n",
    "def plot_num(num_cols):\n",
    "    for col in num_cols:\n",
    "        df[col].plot(kind='kde', title=col)\n",
    "        plt.show()\n",
    "        \n",
    "def plot_cat(cat_cols):\n",
    "    for col in cat_cols:\n",
    "        ax = df[col].value_counts().plot(kind='bar', title=col)\n",
    "        ax.set_ylabel('Count')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a51bf1",
   "metadata": {},
   "source": [
    "Numerical features are observed to generally have a right skewed distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b3c704",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting kernel density estimators for the numerical features\n",
    "plot_num(num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d77ec3",
   "metadata": {},
   "source": [
    "- Categories are generally evenly balanced with the exception of those from Flagged by Carrier and Is International. We especially have to look for imbalance in Scam Call as it affects the accuracy of predicted values. A high imbalance would mean that a randomly selected point is very likely to be classified as the majority class and will have little different from using a model with a high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c7cbbb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting histograms for the categorical features\n",
    "plot_cat(cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e485a",
   "metadata": {},
   "source": [
    "#### Pairplot \n",
    "Pairplots enable us to observe how variables interact with one another and understand correlations and dependencies. From the pairplot with the Scam Call hue, it is clear that we are unable to perform linear classification on the dataset. Instead, we will have to consider classfication methods that involve strategies like kernel tricks and ensemble classifiers to improve classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pairplot(cat_cols):\n",
    "    for col in cat_cols:\n",
    "        pp = sns.pairplot(df, vars=num_cols, hue=col)\n",
    "        pp.fig.suptitle(f'Pairplot with {col} hue', y=1.05)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b97bf1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_pairplot(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2507258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
